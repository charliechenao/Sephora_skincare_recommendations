{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "from collections import defaultdict\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import presence_of_element_located\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.add_argument('--disable-gpu')\n",
    "DRIVER_PATH = 'chromedriver'\n",
    "driver = webdriver.Chrome(options=options, executable_path=DRIVER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting a list of item page URLs from the product list page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to determine how many pages are there in total.\n",
    "start_url = \"https://www.sephora.com/shop/clean-skin-care?pageSize=300&currentPage=1\"\n",
    "\n",
    "# This function will scrape the page at starting_url\n",
    "# and return an integer representing the last pagination number.\n",
    "def find_last_page_number(starting_url):\n",
    "    # request the html using the url, using selenium to take care of the javascript rendering stuff\n",
    "    driver.get(starting_url)\n",
    "    # scroll to bottom\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    last_page_button = soup.find_all(\"button\", class_=\"css-1lk9n5p eanm77i0\")[-1]\n",
    "    return int(last_page_button.text)\n",
    "\n",
    "# This function will scrape and return a list of all products' urls on page_url.\n",
    "def get_product_urls(page_url):\n",
    "    # request the product list page using page_url\n",
    "    driver.get(page_url)\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    # using selenium, we slow-scroll to the bottom to lazy-load all the products\n",
    "    for i in range(1, total_height, 5):\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    # gotta do this twice to account for the last few products\n",
    "    new_total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    for i in range(total_height, new_total_height, 5):\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    # once all products are loaded, we can easily parse the URLs\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    group_elements = soup.find_all(\"div\", class_=\"css-dkxsdo\")\n",
    "    result = []\n",
    "    # for each group, iterate over all 12 of its child elements (individual products)\n",
    "    for g in group_elements:\n",
    "        child_products = g.findChildren(\"div\", class_=\"css-12egk0t\", recursive=False)\n",
    "        for c in child_products:\n",
    "            product = c.findChildren(\"a\", recursive=False)\n",
    "            result.append(\"https://www.sephora.com\" + product[0][\"href\"])\n",
    "    return result\n",
    "\n",
    "# This function combines find_last_page_number and get_product_urls to return a list of \n",
    "# all products across all the pages.\n",
    "def get_all_product_urls(start_url):\n",
    "    last_page_number = find_last_page_number(start_url)\n",
    "    last_page_number = 5\n",
    "    result = []\n",
    "    for i in range(1, last_page_number + 1):\n",
    "        # build out the URL of the current page by changing the currentPage=X part of the URL\n",
    "        current_url = start_url[:-1] + str(i)\n",
    "        current_product_urls = get_product_urls(current_url)\n",
    "        result = result + current_product_urls\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Scrape each product page individually to retrieve the desired features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will scrape the page at starting_url\n",
    "# and return an integer representing the last pagination number for the reviews.\n",
    "def find_last_review_page_number(starting_url):\n",
    "    # request the html using the url, using selenium to take care of the javascript rendering stuff\n",
    "    driver.get(starting_url)\n",
    "    # slowly scroll to the bottom so that the pagination bar fully loads\n",
    "    total_height = int(driver.execute_script(\"return document.body.scrollHeight\"))\n",
    "    # using selenium, we slow-scroll to the bottom to lazy-load all the products\n",
    "    for i in range(1, total_height, 5):\n",
    "        driver.execute_script(\"window.scrollTo(0, {});\".format(i))\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    last_page_button = soup.find_all(\"button\", class_=\"css-exi524\")[-1]\n",
    "    return int(last_page_button.text)\n",
    "\n",
    "# this function requires a beautiful soup document of the sephora product page\n",
    "# the function returns (product brand,name)\n",
    "def scrape_product_name(doc):\n",
    "    product_container = doc.find_all('h1', class_='css-11zrkxf e65zztl0')[0]\n",
    "    product_brand = product_container.findChild(\"a\").text \n",
    "    product_name = product_container.findChild(\"span\").text\n",
    "    return (product_brand, product_name)\n",
    "\n",
    "\n",
    "# scrape review section\n",
    "# this function requires beautiful soup version of the product page\n",
    "# the function returns [beautifulsoup elements] (each element represent a review)\n",
    "# NOTE: this only finds the review section for 1 single page of reviews\n",
    "def scrape_review_section(doc):\n",
    "    return doc.find_all('div', class_=\"css-13o7eu2 eanm77i0\")\n",
    "\n",
    "\n",
    "# function input: single beautifulsoup element representing single review container\n",
    "# function output: extract (product_brand, product_name, skin tone, skin type, star)\n",
    "# if skin tone and skin type were empty, the function will return empty string \n",
    "def extract_review_properties(product_brand, product_name, review):\n",
    "    star = int(review.find('div', class_='css-4qxrld')['aria-label'][0])\n",
    "    skin_attributes = review.find('div', class_=\"css-z04cd8 eanm77i0\").findChild(\"span\")\n",
    "    if skin_attributes is None:\n",
    "        return (product_brand, product_name, \"\", \"\", star)\n",
    "    # split this long string of combined skin attributes into a list of attributes i.e. [eye color, hair color, skin tone, skin type]\n",
    "    skin_attributes_list = skin_attributes.split(\", \")\n",
    "    # extract the elements which contain the word \"skin\" -- ideally we only want the skin type and skin tone attributes\n",
    "    filtered_skin_attributes_list = [i for i in skin_attributes_list if \"skin\" in i]\n",
    "    skin_tone = \"\"\n",
    "    skin_type = \"\"\n",
    "    if len(filtered_skin_attributes_list) == 0: # we do nothing here, leave skin type and skin tone as empty string\n",
    "        pass\n",
    "    if len(filtered_skin_attributes_list) == 1: # user only inputed skin type OR skin tone\n",
    "        if \"skin tone\" in filtered_skin_attributes_list[0]:\n",
    "            skin_tone = filtered_skin_attributes_list[0]\n",
    "        else:\n",
    "            skin_type = filtered_skin_attributes_list[0]\n",
    "        \n",
    "    elif len(filtered_skin_attributes_list) == 2: # user gave both skin type AND skin tone\n",
    "        # sephora inputs skin tone first before skin type\n",
    "        skin_tone = filtered_skin_attributes_list[0]\n",
    "        skin_type = filtered_skin_attributes_list[1]\n",
    "    return (product_brand, product_name, skin_tone, skin_type, star)\n",
    "\n",
    "\n",
    "# function purpose: extract the properties from all the reviews on a single page of reviews\n",
    "# input: the beautifulsoup version of the product page\n",
    "# output: the properties from all the reviews [(skin_tone, skin_type, star)]\n",
    "# remove review that doesn't contain skin type or skin tone\n",
    "# NOTE: this only finds the review section for 1 single page of reviews\n",
    "def extract_reviews_properties(doc):\n",
    "    reviews = scrape_review_section(doc)\n",
    "    product_brand, product_name = scrape_product_name(doc)\n",
    "    reviews_properties = []\n",
    "    for r in reviews:\n",
    "        review_properties = extract_review_properties(product_brand, product_name, r)\n",
    "        if review_properties[0] != '' and review_properties[1] != '':\n",
    "            reviews_properties.append(review_properties)        \n",
    "    return reviews_properties\n",
    "\n",
    "# this function will scrape all the reviews across all the paginated review pages\n",
    "# input: url of the starting page\n",
    "# output: properties from all the reviews across all paginations [(product_brand, product_name, skin_tone, skin_type, star)]\n",
    "def extract_paginated_reviews_properties(start_url):\n",
    "    result = []\n",
    "    total_pages = find_last_review_page_number(start_url)\n",
    "    for i in range(30):\n",
    "        # scrape that page\n",
    "        doc = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        result = result + extract_reviews_properties(doc)\n",
    "        # then press next page only if we are not already on the last page\n",
    "        if i != total_pages - 1:\n",
    "            driver.find_element_by_class_name(\"css-2anst8\").click()\n",
    "    return result      \n",
    "\n",
    "# this function scrapes all the products and all their reviews, saves the output to a csv\n",
    "# input: url of the product list page, csv file name\n",
    "# output: None, but will save a CSV \n",
    "def pipeline(product_list_url, csv_file_name):\n",
    "    products_list = get_all_product_urls(product_list_url)\n",
    "    with open(csv_file_name,'a') as out:\n",
    "        csv_out = csv.writer(out)\n",
    "        csv_out.writerow(['product_brand','product_name', \"skin_tone\", \"skin_type\", \"ratings\"])\n",
    "        for p in products_list:\n",
    "            reviews = extract_paginated_reviews_properties(p)\n",
    "            for r in reviews:\n",
    "                csv_out.writerow(r)\n",
    "    out.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-c89e2b61ddab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"https://www.sephora.com/shop/clean-skin-care?currentPage=1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"./test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-156-2c95145257b5>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(product_list_url, csv_file_name)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mcsv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'product_brand'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'product_name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skin_tone\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skin_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ratings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproducts_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_paginated_reviews_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0mcsv_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-2c95145257b5>\u001b[0m in \u001b[0;36mextract_paginated_reviews_properties\u001b[0;34m(start_url)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# scrape that page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextract_reviews_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;31m# then press next page only if we are not already on the last page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtotal_pages\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-2c95145257b5>\u001b[0m in \u001b[0;36mextract_reviews_properties\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mreviews_properties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreviews\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mreview_properties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_review_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct_brand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreview_properties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreview_properties\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mreviews_properties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreview_properties\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-2c95145257b5>\u001b[0m in \u001b[0;36mextract_review_properties\u001b[0;34m(product_brand, product_name, review)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproduct_brand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproduct_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# split this long string of combined skin attributes into a list of attributes i.e. [eye color, hair color, skin tone, skin type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mskin_attributes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskin_attributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;31m# extract the elements which contain the word \"skin\" -- ideally we only want the skin type and skin tone attributes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mfiltered_skin_attributes_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskin_attributes_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"skin\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "pipeline(\"https://www.sephora.com/shop/clean-skin-care?currentPage=1\", \"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
